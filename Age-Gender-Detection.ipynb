{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 faces\n",
      "Gender : Female\n",
      "Age Range: (25, 32)\n",
      "Found 1 faces\n",
      "Gender : Female\n",
      "Age Range: (25, 32)\n",
      "Found 1 faces\n",
      "Gender : Female\n",
      "Age Range: (15, 20)\n",
      "Found 1 faces\n",
      "Gender : Female\n",
      "Age Range: (8, 12)\n",
      "Found 1 faces\n",
      "Gender : Female\n",
      "Age Range: (25, 32)\n",
      "Found 1 faces\n",
      "Gender : Female\n",
      "Age Range: (25, 32)\n",
      "Found 1 faces\n",
      "Gender : Female\n",
      "Age Range: (25, 32)\n",
      "Found 1 faces\n",
      "Gender : Female\n",
      "Age Range: (25, 32)\n",
      "Found 1 faces\n",
      "Gender : Female\n",
      "Age Range: (25, 32)\n",
      "Found 1 faces\n",
      "Gender : Female\n",
      "Age Range: (25, 32)\n",
      "Found 1 faces\n",
      "Gender : Female\n",
      "Age Range: (25, 32)\n",
      "Found 1 faces\n",
      "Gender : Female\n",
      "Age Range: (38, 43)\n",
      "Found 1 faces\n",
      "Gender : Female\n",
      "Age Range: (15, 20)\n",
      "Found 1 faces\n",
      "Gender : Female\n",
      "Age Range: (15, 20)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Nov 19 10:36:03 2018\n",
    "@author: Kishore1\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "#import imutils\n",
    "#import time\n",
    "import numpy as np\n",
    "import pafy\n",
    "\n",
    "#url of the video to do face \n",
    "url = 'https://www.youtube.com/watch?v=iH1ZJVqJO3Y'\n",
    "vPafy = pafy.new(url)\n",
    "play = vPafy.getbest(preftype=\"mp4\")\n",
    "\n",
    "#Often, we have to capture live stream with camera. OpenCV provides a very simple interface to this.\n",
    "#Let's capture a video from the camera (I am using the in-built webcam of my laptop), convert it into grayscale video and display it. Just a simple task to get started.\n",
    "#To capture a video, you need to create a VideoCapture object. Its argument can be either the device index or the name of a video file. Device index is just the number to specify which camera. Normally one camera will be connected (as in my case). So I simply pass 0 (or -1). You can select the second camera by passing 1 and so on. After that, you can capture frame-by-frame.\n",
    "cap = cv2.VideoCapture(0)\n",
    "#cap.set(propId, value). Value is the new value you want.\n",
    "cap.set(3, 480) #set width of the frame\n",
    "cap.set(4, 640) #set height of the frame\n",
    "\n",
    "MODEL_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746)\n",
    "age_list = ['(0, 2)', '(4, 6)', '(8, 12)', '(15, 20)', '(25, 32)', '(38, 43)', '(48, 53)', '(60, 100)']\n",
    "gender_list = ['Male', 'Female']\n",
    "\n",
    "def initialize_caffe_models():\n",
    "\t#load .prototxt and caffemodel for both gender and Age\n",
    "\tage_net = cv2.dnn.readNetFromCaffe('deploy_age.prototxt', 'age_net.caffemodel') \n",
    "\n",
    "\tgender_net = cv2.dnn.readNetFromCaffe('deploy_gender.prototxt', 'gender_net.caffemodel')\n",
    "\n",
    "\treturn(age_net, gender_net)\n",
    "\n",
    "def read_from_camera(age_net, gender_net):\n",
    "\tfont = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "\twhile True:\n",
    "\n",
    "       #cap.read() returns a bool (True/False). If frame is read correctly, it will be True.\n",
    "       #So you can check end of the video by checking this return value.\n",
    "       #Sometimes, cap may not have initialized the capture. In that case, this code shows error. \n",
    "       #You can check whether it is initialized or not by the method cap.isOpened(). If it is True, OK. Otherwise open it using cap.open().\n",
    "\t\tret, image = cap.read()\n",
    "       \n",
    "       #load pre built model for facial recognition\n",
    "\t\tface_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    " \n",
    "\t\tgray = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\t\tfaces = face_cascade.detectMultiScale(gray, 1.1, 5)\n",
    "\n",
    "\t\tif(len(faces)>0):\n",
    "\t\t\tprint(\"Found {} faces\".format(str(len(faces))))\n",
    "\n",
    "\t\tfor (x, y, w, h )in faces:\n",
    "\t\t\tcv2.rectangle(image, (x, y), (x+w, y+h), (255, 255, 0), 2)\n",
    "\n",
    "\t\t\t# Get Face \n",
    "\t\t\tface_img = image[y:y+h, h:h+w].copy()\n",
    "\t\t\tblob = cv2.dnn.blobFromImage(face_img, 1, (227, 227), MODEL_MEAN_VALUES, swapRB=False)\n",
    "\n",
    "\t\t\t#Predict Gender\n",
    "\t\t\tgender_net.setInput(blob)\n",
    "\t\t\tgender_preds = gender_net.forward()\n",
    "\t\t\tgender = gender_list[gender_preds[0].argmax()]\n",
    "\t\t\tprint(\"Gender : \" + gender)\n",
    "\n",
    "\t\t\t#Predict Age\n",
    "\t\t\tage_net.setInput(blob)\n",
    "\t\t\tage_preds = age_net.forward()\n",
    "\t\t\tage = age_list[age_preds[0].argmax()]\n",
    "\t\t\tprint(\"Age Range: \" + age)\n",
    "\n",
    "\t\t\toverlay_text = \"%s %s\" % (gender, age)\n",
    "\t\t\tcv2.putText(image, overlay_text, (x, y), font, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "\t\tcv2.imshow('frame', image)\n",
    "       #0xFF is a hexadecimal constant which is 11111111 in binary.\n",
    "       #By using bitwise AND (&) with this constant, it leaves only the last 8 bits of the original (in this case, whatever cv2.waitKey(0) is).\n",
    "\t\tif cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "\t\t\tbreak\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\tage_net, gender_net = initialize_caffe_models()\n",
    "\n",
    "\tread_from_camera(age_net, gender_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
